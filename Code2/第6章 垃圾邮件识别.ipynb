{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2　特征提取\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import os\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_1d, global_max_pool\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.merge_ops import merge\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "import pandas as pd\n",
    "# from tensorflow.contrib import learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.1　词袋模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer=CountVectorizer(min_df=1)\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?'\n",
    "]\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out() == (['and', 'document', 'first', 'is', 'one',\n",
    "                                    'second', 'the', 'third', 'this'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 2, 1, 0, 1],\n",
       "       [1, 0, 0, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = vectorizer.vocabulary_\n",
    "new_vectorizer = CountVectorizer(min_df=1, vocabulary=vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=5000\n",
    "max_document_length=100\n",
    "\n",
    "def load_one_file(filename):\n",
    "    x=\"\"\n",
    "    with open(filename, encoding='utf-8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            line=line.strip('\\n')\n",
    "            line = line.strip('\\r')\n",
    "            x+=line\n",
    "    return x\n",
    "\n",
    "def load_files_from_dir(rootdir):\n",
    "    x=[]\n",
    "    list = os.listdir(rootdir)\n",
    "    for i in range(0, len(list)):\n",
    "        path = os.path.join(rootdir, list[i])\n",
    "        if os.path.isfile(path):\n",
    "            # print(path)\n",
    "            v=load_one_file(path)\n",
    "            x.append(v)\n",
    "    return x\n",
    "\n",
    "def load_all_files():\n",
    "    ham=[]\n",
    "    spam=[]\n",
    "    for i in range(1,2):\n",
    "        path=\"../Data/mail/enron%d/ham/\" % i\n",
    "        print(\"Load %s\" % path)\n",
    "        ham+=load_files_from_dir(path)\n",
    "        path=\"../Data/mail/enron%d/spam/\" % i\n",
    "        print(\"Load %s\" % path)\n",
    "        spam+=load_files_from_dir(path)\n",
    "    return ham,spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用词袋模型，向量化正常邮件和垃圾邮件样本，其中ham文件夹下的样本标记为0，表示正常邮件，spam文件夹下的样本标记为1，表示垃圾邮件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ../Data/mail/enron1/ham/\n",
      "Load ../Data/mail/enron1/spam/\n"
     ]
    }
   ],
   "source": [
    "ham, spam=load_all_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>垃圾邮件</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: dobmeos with hgh my energy level has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: your prescription is ready . . oxwq s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: get that new car 8434people nowthe we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: await your responsedear partner ,we a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: coca cola , mbna america , nascar par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>Subject: our pro - forma invoice attacheddivid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>Subject: str _ rndlen ( 2 - 4 ) } { extra _ ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>Subject: check me out !61 bbhey dermbbbbbcheck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>Subject: hot jobsglobal marketing specialties ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>Subject: save up to 89 % on ink + no shipping ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   垃圾邮件\n",
       "0     Subject: dobmeos with hgh my energy level has ...\n",
       "1     Subject: your prescription is ready . . oxwq s...\n",
       "2     Subject: get that new car 8434people nowthe we...\n",
       "3     Subject: await your responsedear partner ,we a...\n",
       "4     Subject: coca cola , mbna america , nascar par...\n",
       "...                                                 ...\n",
       "1495  Subject: our pro - forma invoice attacheddivid...\n",
       "1496  Subject: str _ rndlen ( 2 - 4 ) } { extra _ ti...\n",
       "1497  Subject: check me out !61 bbhey dermbbbbbcheck...\n",
       "1498  Subject: hot jobsglobal marketing specialties ...\n",
       "1499  Subject: save up to 89 % on ink + no shipping ...\n",
       "\n",
       "[1500 rows x 1 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(spam,columns=['垃圾邮件'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>正常邮件</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: christmas tree farm pictures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: vastar resources , inc .gary , produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: calpine daily gas nomination- calpine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: re : issuefyi - see note below - alre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: meter 7268 nov allocationfyi .- - - -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3667</th>\n",
       "      <td>Subject: re : tenaska ivi ' ll call you on thu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3668</th>\n",
       "      <td>Subject: generic contracthi daren ,sorry for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3669</th>\n",
       "      <td>Subject: re : contracts and creditthanks - - i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3670</th>\n",
       "      <td>Subject: re : tenaska ivok , since we don ' t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3671</th>\n",
       "      <td>Subject: re : tenaska ivi tried calling you th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3672 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   正常邮件\n",
       "0                 Subject: christmas tree farm pictures\n",
       "1     Subject: vastar resources , inc .gary , produc...\n",
       "2     Subject: calpine daily gas nomination- calpine...\n",
       "3     Subject: re : issuefyi - see note below - alre...\n",
       "4     Subject: meter 7268 nov allocationfyi .- - - -...\n",
       "...                                                 ...\n",
       "3667  Subject: re : tenaska ivi ' ll call you on thu...\n",
       "3668  Subject: generic contracthi daren ,sorry for t...\n",
       "3669  Subject: re : contracts and creditthanks - - i...\n",
       "3670  Subject: re : tenaska ivok , since we don ' t ...\n",
       "3671  Subject: re : tenaska ivi tried calling you th...\n",
       "\n",
       "[3672 rows x 1 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ham,columns=['正常邮件'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_features_by_wordbag():\n",
    "    ham, spam=load_all_files()\n",
    "    x=ham+spam\n",
    "    y=[0]*len(ham)+[1]*len(spam)\n",
    "    vectorizer = CountVectorizer(\n",
    "                                 decode_error='ignore', # 处理解码失败的方式，分为“strict”​“ignore”​“replace”3种方式\n",
    "                                 strip_accents='ascii',\n",
    "                                 max_features=max_features,\n",
    "                                 stop_words='english',\n",
    "                                 max_df=1.0,\n",
    "                                 min_df=1 )\n",
    "    print(vectorizer)\n",
    "    x=vectorizer.fit_transform(x)\n",
    "    x=x.toarray()\n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_all_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1021421fed66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_features_by_wordbag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-76298e8db925>\u001b[0m in \u001b[0;36mget_features_by_wordbag\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_features_by_wordbag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mham\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspam\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload_all_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mham\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mspam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mham\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     vectorizer = CountVectorizer(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_all_files' is not defined"
     ]
    }
   ],
   "source": [
    "x,y = get_features_by_wordbag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5171</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5172 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...  4990  \\\n",
       "0        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1        2    18     0     0     0     0     0     0     0     0  ...     0   \n",
       "2        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "5167     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "5168     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "5169     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "5170     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "5171     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "      4991  4992  4993  4994  4995  4996  4997  4998  4999  \n",
       "0        0     0     0     0     0     0     0     0     0  \n",
       "1        0     0     0     0     0     0     0     0     0  \n",
       "2        0     0     0     0     0     0     0     0     0  \n",
       "3        0     0     0     0     0     0     0     0     0  \n",
       "4        0     0     0     0     0     0     0     0     0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "5167     0     0     0     0     0     0     0     0     0  \n",
       "5168     0     0     0     0     0     0     0     0     0  \n",
       "5169     0     0     0     0     0     0     0     0     0  \n",
       "5170     0     0     0     0     0     0     0     0     0  \n",
       "5171     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5172 rows x 5000 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "4995    0\n",
       "4996    0\n",
       "4997    0\n",
       "4998    0\n",
       "4999    0\n",
       "Name: 0, Length: 5000, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t= pd.DataFrame(x)\n",
    "t.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       2\n",
       "7       1\n",
       "17      1\n",
       "36      1\n",
       "37      5\n",
       "       ..\n",
       "5085    1\n",
       "5110    2\n",
       "5114    2\n",
       "5151    1\n",
       "5154    1\n",
       "Name: 0, Length: 626, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[t[0]!=0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.2　TF-IDF模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(smooth_idf=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义了一个名为counts的列表，其中包含了多个子列表。每个子列表代表一个文档中词语出现的次数（这里简化为二维数组，每个子列表代表一个文档，列表中的数字代表词语出现的次数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [[3, 0, 1],\n",
    "        [2, 0, 0],\n",
    "        [3, 0, 0], \n",
    "        [4, 0, 0], \n",
    "        [3, 2, 0], \n",
    "        [3, 0, 2]]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用Tfidf方法从transformer模块中，将counts矩阵转换为TF-IDF矩阵。fit_transform方法计算了每个词语的TF-IDF值，并将结果存储在变量tfidf中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = transformer.fit_transform(counts)\n",
    "tfidf        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印tfidf变量，显示转换后的TF-IDF矩阵。输出显示这是一个稀疏矩阵，意味着很多值都是0，这在处理大型数据集时可以节省内存和计算资源。\n",
    "\n",
    "调用tfidf.toarray()方法将稀疏矩阵转换为常规的NumPy数组，以便更直观地查看转换后的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81940995, 0.        , 0.57320793],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.47330339, 0.88089948, 0.        ],\n",
       "       [0.58149261, 0.        , 0.81355169]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印转换后的数组，显示了每个词语在每个文档中的TF-IDF值。TF-IDF值越高，表示词语在文档中越重要，但在整个文档集合中不那么常见"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ../Data/mail/enron1/ham/\n",
      "Load ../Data/mail/enron1/spam/\n",
      "CountVectorizer(binary=True, decode_error='ignore', max_features=5000,\n",
      "                stop_words='english', strip_accents='ascii')\n",
      "TfidfTransformer(smooth_idf=False)\n"
     ]
    }
   ],
   "source": [
    "def get_features_by_wordbag_tfidf():\n",
    "    ham, spam=load_all_files()\n",
    "    x=ham+spam\n",
    "    y=[0]*len(ham)+[1]*len(spam)\n",
    "    vectorizer = CountVectorizer(binary=True,\n",
    "                                 decode_error='ignore',\n",
    "                                 strip_accents='ascii',\n",
    "                                 max_features=max_features,\n",
    "                                 stop_words='english',\n",
    "                                 max_df=1.0,\n",
    "                                 min_df=1 )\n",
    "    print(vectorizer)\n",
    "    x=vectorizer.fit_transform(x)\n",
    "    x=x.toarray()\n",
    "    transformer = TfidfTransformer(smooth_idf=False)\n",
    "    print(transformer)\n",
    "    tfidf = transformer.fit_transform(x)\n",
    "    x = tfidf.toarray()\n",
    "    return  x,y\n",
    "    \n",
    "x,y = get_features_by_wordbag_tfidf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.067431</td>\n",
       "      <td>0.061318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5171</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5172 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1     2     3     4     5     6     7     8     9     ...  \\\n",
       "0     0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "1     0.067431  0.061318   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2     0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "3     0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "4     0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "...        ...       ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "5167  0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "5168  0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "5169  0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "5170  0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "5171  0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "\n",
       "      4990  4991  4992  4993  4994  4995  4996  4997  4998  4999  \n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "5167   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "5168   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "5169   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "5170   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "5171   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5172 rows x 5000 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.3　词汇表模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_text =[\n",
    "#         'i love you',\n",
    "#         'me too']\n",
    "# vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(\n",
    "#                                 max_document_length,\n",
    "#                                 min_frequency=0,\n",
    "#                                 vocabulary=None,\n",
    "#                                 tokenizer_fn=None)\n",
    "# vocab_processor.fit(x_text)\n",
    "# next(vocab_processor.transform(x_text)).tolist()\n",
    "# x = np.array(list(vocab_processor.fit_transform(x_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5]]\n"
     ]
    }
   ],
   "source": [
    "x_text = [\n",
    "    'i love you',\n",
    "    'me too'\n",
    "]\n",
    "\n",
    "# 创建一个Tokenizer对象\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=None,  # 如果为 None，则词汇表大小由文本数据动态确定\n",
    "    lower=True  # 是否将文本转换为小写\n",
    ")\n",
    "\n",
    "# 使用文本数据拟合Tokenizer\n",
    "tokenizer.fit_on_texts(x_text)\n",
    "\n",
    "# 使用tokenizer转换文本\n",
    "encoded_text = tokenizer.texts_to_sequences(x_text)\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4, 5]]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"i me too\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ../Data/mail/enron1/ham/\n",
      "Load ../Data/mail/enron1/spam/\n"
     ]
    }
   ],
   "source": [
    "# def get_features_by_tf():\n",
    "#     global  max_document_length\n",
    "#     x=[]\n",
    "#     y=[]\n",
    "#     ham, spam=load_all_files()\n",
    "#     x=ham+spam\n",
    "#     y=[0]*len(ham)+[1]*len(spam)\n",
    "#     vp=tflearn.data_utils.VocabularyProcessor(max_document_length=max_document_length,\n",
    "#                                               min_frequency=0,\n",
    "#                                               vocabulary=None,\n",
    "#                                               tokenizer_fn=None)\n",
    "#     x=vp.fit_transform(x, unused_y=None)\n",
    "#     x=np.array(list(x))\n",
    "#     return x,y\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def get_features_by_tf():\n",
    "    global max_document_length\n",
    "    x = []\n",
    "    y = []\n",
    "    ham, spam = load_all_files()\n",
    "    x = ham + spam\n",
    "    y = [0] * len(ham) + [1] * len(spam)\n",
    "\n",
    "    # Initialize the Tokenizer\n",
    "    tokenizer = Tokenizer(num_words=max_features, oov_token='<OOV>')\n",
    "    tokenizer.fit_on_texts(x)\n",
    "\n",
    "    # Convert texts to sequences\n",
    "    x = tokenizer.texts_to_sequences(x)\n",
    "\n",
    "    # Pad sequences to ensure uniform input size\n",
    "    x = pad_sequences(x, maxlen=max_document_length, padding='post')\n",
    "\n",
    "    return x, y\n",
    "\n",
    "x, y = get_features_by_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>3083</td>\n",
       "      <td>4959</td>\n",
       "      <td>4418</td>\n",
       "      <td>2058</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>411</td>\n",
       "      <td>104</td>\n",
       "      <td>47</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>411</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>411</td>\n",
       "      <td>647</td>\n",
       "      <td>47</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>640</td>\n",
       "      <td>222</td>\n",
       "      <td>36</td>\n",
       "      <td>185</td>\n",
       "      <td>640</td>\n",
       "      <td>222</td>\n",
       "      <td>36</td>\n",
       "      <td>185</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>471</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>202</td>\n",
       "      <td>111</td>\n",
       "      <td>150</td>\n",
       "      <td>53</td>\n",
       "      <td>88</td>\n",
       "      <td>1087</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>63</td>\n",
       "      <td>111</td>\n",
       "      <td>127</td>\n",
       "      <td>13</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1362</td>\n",
       "      <td>65</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>34</td>\n",
       "      <td>1328</td>\n",
       "      <td>2224</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>86</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>1190</td>\n",
       "      <td>282</td>\n",
       "      <td>2</td>\n",
       "      <td>2059</td>\n",
       "      <td>129</td>\n",
       "      <td>492</td>\n",
       "      <td>1</td>\n",
       "      <td>941</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "      <td>986</td>\n",
       "      <td>1</td>\n",
       "      <td>712</td>\n",
       "      <td>1</td>\n",
       "      <td>770</td>\n",
       "      <td>390</td>\n",
       "      <td>1835</td>\n",
       "      <td>2068</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>1823</td>\n",
       "      <td>116</td>\n",
       "      <td>65</td>\n",
       "      <td>1531</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>15</td>\n",
       "      <td>415</td>\n",
       "      <td>43</td>\n",
       "      <td>90</td>\n",
       "      <td>2295</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>15</td>\n",
       "      <td>1321</td>\n",
       "      <td>1</td>\n",
       "      <td>595</td>\n",
       "      <td>1</td>\n",
       "      <td>3071</td>\n",
       "      <td>803</td>\n",
       "      <td>827</td>\n",
       "      <td>911</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5171</th>\n",
       "      <td>15</td>\n",
       "      <td>444</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>2374</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>201</td>\n",
       "      <td>225</td>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5172 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3     4     5    6    7     8     9   ...   90    91  \\\n",
       "0      15  3083  4959  4418  2058     0    0    0     0     0  ...    0     0   \n",
       "1     120     1   182   411   104    47  120    1   182   411  ...  122     1   \n",
       "2      15   640   222    36   185   640  222   36   185    41  ...    0     0   \n",
       "3     471   165     1   202   111   150   53   88  1087    99  ...    6    63   \n",
       "4       1    73    34  1328  2224    11    4   13    86    53  ...   31  1190   \n",
       "...   ...   ...   ...   ...   ...   ...  ...  ...   ...   ...  ...  ...   ...   \n",
       "5167   15    49   986     1   712     1  770  390  1835  2068  ...    0     0   \n",
       "5168   15     1     1    45    65  1823  116   65  1531     1  ...    0     0   \n",
       "5169   15   415    43    90  2295     1    1   90     1     5  ...    0     0   \n",
       "5170   15  1321     1   595     1  3071  803  827   911     1  ...    0     0   \n",
       "5171   15   444    75     3  2374    13    1   82   845     1  ...   23     1   \n",
       "\n",
       "       92   93    94   95   96    97   98   99  \n",
       "0       0    0     0    0    0     0    0    0  \n",
       "1     182  411   647   47  122     1  182  411  \n",
       "2       0    0     0    0    0     0    0    0  \n",
       "3     111  127    13   42    1  1362   65  111  \n",
       "4     282    2  2059  129  492     1  941   60  \n",
       "...   ...  ...   ...  ...  ...   ...  ...  ...  \n",
       "5167    0    0     0    0    0     0    0    0  \n",
       "5168    0    0     0    0    0     0    0    0  \n",
       "5169    0    0     0    0    0     0    0    0  \n",
       "5170    0    0     0    0    0     0    0    0  \n",
       "5171  201  225     3   89  145     1   32  624  \n",
       "\n",
       "[5172 rows x 100 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3　模型训练与验证\n",
    "\n",
    "## 6.3.1　朴素贝叶斯算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_nb_wordbag(x_train, x_test, y_train, y_test):\n",
    "    print(\"NB and wordbag\")\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(x_train,y_train)\n",
    "    y_pred=gnb.predict(x_test)\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ../Data/mail/enron1/ham/\n",
      "Load ../Data/mail/enron1/spam/\n",
      "CountVectorizer(decode_error='ignore', max_features=5000, stop_words='english',\n",
      "                strip_accents='ascii')\n"
     ]
    }
   ],
   "source": [
    "x,y = get_features_by_wordbag()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4, random_state = 0)\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train,y_train)\n",
    "y_pred=gnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555340744320928"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1405,   58],\n",
       "       [  34,  572]], dtype=int64)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features=1000\n",
      "Load ../Data/mail/enron1/ham/\n",
      "Load ../Data/mail/enron1/spam/\n",
      "CountVectorizer(decode_error='ignore', max_features=1000, stop_words='english',\n",
      "                strip_accents='ascii')\n",
      "max_features=3000\n",
      "Load ../Data/mail/enron1/ham/\n",
      "Load ../Data/mail/enron1/spam/\n",
      "CountVectorizer(decode_error='ignore', max_features=3000, stop_words='english',\n",
      "                strip_accents='ascii')\n",
      "max_features=5000\n",
      "Load ../Data/mail/enron1/ham/\n",
      "Load ../Data/mail/enron1/spam/\n",
      "CountVectorizer(decode_error='ignore', max_features=5000, stop_words='english',\n",
      "                strip_accents='ascii')\n",
      "max_features=7000\n",
      "Load ../Data/mail/enron1/ham/\n",
      "Load ../Data/mail/enron1/spam/\n",
      "CountVectorizer(decode_error='ignore', max_features=7000, stop_words='english',\n",
      "                strip_accents='ascii')\n",
      "max_features=9000\n",
      "Load ../Data/mail/enron1/ham/\n",
      "Load ../Data/mail/enron1/spam/\n",
      "CountVectorizer(decode_error='ignore', max_features=9000, stop_words='english',\n",
      "                strip_accents='ascii')\n",
      "max_features=11000\n",
      "Load ../Data/mail/enron1/ham/\n",
      "Load ../Data/mail/enron1/spam/\n",
      "CountVectorizer(decode_error='ignore', max_features=11000, stop_words='english',\n",
      "                strip_accents='ascii')\n",
      "max_features=13000\n",
      "Load ../Data/mail/enron1/ham/\n",
      "Load ../Data/mail/enron1/spam/\n",
      "CountVectorizer(decode_error='ignore', max_features=13000, stop_words='english',\n",
      "                strip_accents='ascii')\n",
      "max_features=15000\n",
      "Load ../Data/mail/enron1/ham/\n",
      "Load ../Data/mail/enron1/spam/\n",
      "CountVectorizer(decode_error='ignore', max_features=15000, stop_words='english',\n",
      "                strip_accents='ascii')\n",
      "max_features=17000\n",
      "Load ../Data/mail/enron1/ham/\n",
      "Load ../Data/mail/enron1/spam/\n",
      "CountVectorizer(decode_error='ignore', max_features=17000, stop_words='english',\n",
      "                strip_accents='ascii')\n",
      "max_features=19000\n",
      "Load ../Data/mail/enron1/ham/\n",
      "Load ../Data/mail/enron1/spam/\n",
      "CountVectorizer(decode_error='ignore', max_features=19000, stop_words='english',\n",
      "                strip_accents='ascii')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEXCAYAAABVr8jJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAA49klEQVR4nO3debxVVf3/8debSUBQxhQBEWcxTfBqjkFkhmYgqIU5a2Kppd/Esckwc8hMTVNREdEMx4xKQ0PJfjnERWYUxSkvoCKDiMj8+f2x1vFuDnfal3PuvsPn+Xicx9ln7emzzz33fM7ea+21ZGY455xzaTTLOgDnnHMNjycP55xzqXnycM45l5onD+ecc6l58nDOOZeaJw/nnHOpefJwm5C0UtLOWcfhXEUktZH0V0kfS3ok63iaMk8eTYSkyZK+V91yZtbOzN6qi5hccUm6TNLzFZR3kbRW0hcltZL0W0ll8YfDO5JuyiDcmjoe2A7obGYnbMmGJF0p6YHChNX0ePJwAEhqkXUMhdZIj6l5isUfAA6R1DuvfDgwy8xmA5cDJcCBQHtgAPBKAUItll7A62a2PutAGuPnKxUz80c9fQDvABcDM4FPgXsIv7qeAj4B/gl0TCx/EPACsByYAQyI5VcDG4DVwErg1lhuwHnAG8DbibJd43Qb4LfAu8DHwP+LZa0JX0xL4r6mANtVcgw3A+8BK4CpwOGJec2BK4A34/FMBXrGeXsDzwBLgQ+AK2L5WOBXiW0MAMry3rNL43u2BmgBXJbYx1xgaF6MZwOvJub3i+/7Y3nL3QLcXM3f7HTgrbitt4GTqtpPLN8LmBzfyznA4MQ6Y4HbgSfjZ+AIYAfgMWBx3MePqojnaeDneWX/BS6I038DLkzxmTTg3PiZ+QS4CtiF8LlbATwMtIrLdozbXwwsi9M94rxOQBnwrfi6HTAfOLWKff8SWAusI3yOz4rlZ8b3dRkwEehV3ecPGJS3rRmJz88RifWvBB6I0zvF4z8L+B/wfFX7BwT8Dvgw7n8W8MWsv1cK9cg8AH9U8ccJH+SXCAmje/wQvgL0JXyBPwv8Ii7bnfBlfjThjPLr8XXXOH8y8L287RvhC7oT0CZRlkset8X1uhO+6A8BtgLOAf4KtI3l+wPbVHIMJwOdCV/iFwHvA63jvIvjP9Qe8R/tS3HZ9sCiuHzr+PrLcZ2xVJ88pgM9E8d0AuELtxnwHcKXcLfEvAXAATGGXQm/brvF5TrE5VrE93//Kv5eW8cviT3i627A3tXspyXhS/MKoBUwkPClvEfieD8GDo3xtyV8Cf48Lr8zIVl9o5KYTgLeSLzeg/Clmftc/JTwRXgusA+gaj6TBvwF2IaQ4NcAk2Ic2xKS4mlx2c7AcTHm9sAjwBOJbR0ZPw9fAO4CHq3B/8SVxC/z+HpIfP/2in+jnwIv1PDzt8m2Ep+f6pLHuPi3blPV/oFvxL9Vh/g334v4uWsMj8wD8EcVf5zwQU7+cn0MuD3x+oe5f0bCr+3789afmPhHnkzFyWNgBWW7xi+qz4AvVRDXmYRfmvvW4piW5bYJzAOGVLDMicC0StYfS/XJ48xqYpie2298jy6oZLmngLPj9DHA3Gq2uzXh7OE4YuLK+1tsth/g8PiF1ixR9ifgysTxjkvM+zLwv7xtXA7cW0lMbQkJ7ZD4+mrgL4n5zQlnn/8hJIKFuc9MJdsz4NDE66nApYnXvwVuqmTd/YBleWW/J/yAWECox6ju83MlmyaPp4hnIPF1M2AVibOPKj5/m2wr8fmpLnnsXJP9E34IvE64ItCsumNraA+v86j/PkhMf1bB63ZxuhdwgqTluQdwGOHXb1Xeq6S8C+FX/5sVzLuf8GU4XtJCSddLalnRRiSNlPRqbB2znPDrtEuc3bOS7VdWXlObHJOkUyVNT7wvX6xBDAD3EX65Ep/vr2qnZvYp4czm+8AiSX+XtGc1+9kBeM/MNibK3iWc7VV0PL2AHfL+zlcQzk4rimkV4Rf/qZJEOBMZl5i/wcxuM7NDCb+QrwbGSNqrikOt0WdSUltJd0p6V9IK4HmgQ169zWjC32OsmS2pYp+V6QXcnHgvlhJ+5XePMVT1+aut/L9Hhfs3s2eBWwln8B9KGi1pmy3cd73hyaPxeI9w5tEh8djazK6N862S9Sor/4hQR7LLZiuYrTOzX5pZH8KlrGOAU/OXk3Q4cAnwbULdTAfCJRglYt5s+7G8subCnxJ+TedsX8Eynx+TpF6ESyLnE37ZdgBm1yAGgCeAfSV9kXCMf6xkufIdm000s68TkvZrcd9V7Wch0FNS8n9xR8Iv8c2OJ27n7by/c3szO7qKsO4j/A2+Trh89NdKYv/MzG4j/DrvU8X2auoiwmWyL5vZNsBXYrng88r/0YRkdq6kXWuxj/eAc/LejzZm9kINPn8VffZTfb6q2j+Amd1iZvsT3s/dCZdqGwVPHo3HA8C3JH1DUnNJrSUNkNQjzv+Ayr+QNxN/CY8BbpS0Q9zmwZK2kvRVSfvEf/4VhErHjRVspj2wnlBh2kLSzwnXynPuBq6StJuCfSV1JlSsdpN0Ydxfe0lfjutMB46W1EnS9sCF1RzK1oR/9sUAks4g/NJNxjBS0v4xhl1jwsHMVgOPAg8C/zWz/1W1I0nbSRoiaWvCJaCVifelsv28TLjMcYmklpIGAN8Cxleym/8Cn0i6NN7z0Dw2uT2gitD+TbicNhoYb2ZrEzFfGD8nbSS1kHQa4e82rapjraH2hDOR5ZI6Ab/Im38F4W9zJvAbYFzK1mQAdwCXS9obQNK2knJNeKv7/H0A7JSXuKcDw+PfooTQNLhW+5d0gKQvx7PyTwk/xir6P2mQPHk0Emb2HqHy7grCP8t7hF85ub/xzcDxkpZJuqWGmx1JuB49hXA6fl3c3vaEL9UVhFYm/yJe0pF0h6Q74voTgX8Qrvu+S/jnSZ7y30honfN03NY9hLqCTwi/kr9FqA94A/hqXOd+Qkuyd+J6D1XzvswlXId/kfBlsQ/h+n5u/iOESzUPEiqqnyA0IMi5L65T5SWrqBnwY8LZxFKgP/CDqvYTv8i/BRxFONv7A6HF0WuVHM8GwlnQfoSWVh8REtO2VbwHuUreXiQuWUWrCO/P+3Fb5wHHWWHu9bmJUKn8EaHhxz9yMyTtT3ivTo3HdB0hkVyWZgdm9ue47vh4aWw24b2E6j9/uZsMl0jKNU/+GeEMcRmhddeDW7D/bQhnnsvi/pcQkmSjoFjJ45yrgKQdCZeftjezFVnH41x94WcezlUiXs74MeFSjycO5xKa9h2SzlUi1lt8QLjcMChv3spKVjvKzP5d7NgaO0lzCJfY8p1jZtU2WnB1wy9bOeecS80vWznnnEut6JetJA0itPRpDtyduO8gN78XoUloV0ILlZPNrEzSVwn9wuTsCQw3sycUOnobT+h2YCpwSrL5YUW6dOliO+20U4GOyjnnmoapU6d+ZGZd88uLetkqttl+ndDssozQ5PPE2Hwyt8wjwN/M7D5JA4EzzOyUvO10IvQf08PMVkl6GHjczMbHZqEzzOz2qmIpKSmx0tLSgh6fc841dpKmmllJfnmxL1sdCMw3s7fimcF4wr0ISX0IHfwBPFfBfAg36jwVE4cIfcY8GufdBxxb6MCdc85VrtjJozub3pRTxqZ99kC44WtYnB4KtI93GScNJ3QWB+FS1XIr78+/om0CIGmEpFJJpYsXL67lITjnnMtXHyrMRwL9JU0j3JG7gDD2BACSuhHu8J2YdsNmNtrMSsyspGvXzS7ZOeecq6ViV5gvIPQmmtODTTt8w8wWEs88JLUjdI2wPLHIt4E/m9m6+HoJoWfOFvHsY7NtOuec29y6desoKytj9erVm81r3bo1PXr0oGXLCjvI3kyxk8cUYLfYOmoB4fLTd5MLSOoCLI0d8V1OaHmVdGIsB0I/PZKeI9SDjAdOIwxO45xzrgplZWW0b9+enXbaiVB9HJgZS5YsoaysjN6980ctrlhRL1vFM4PzCZecXgUeNrM5kkZJGhwXGwDMk/Q6YUyCq3PrS9qJcObyr7xNXwr8WNJ8Qh3IPcU8DuecawxWr15N586dN0kcAJLo3LlzhWcklSn6fR5m9iRh/OVk2c8T049S3nIqf913qKAyPPb4eWBBA3XOuSYgP3FUV16Z+lBh7pxzjcvcuXDSSbCi8fan6R0jOudcoTz0EPz0pzB/fni9ciX8pXFWyfqZh3PObYnVq+Hii2HbbWH48JA49t4bhg2DCRNCQqlHKutVJG1vI548nHOuNt5+G775TWjXDm64AVatgmOOCeWzZ8P48XDIIfC978Grr2YdLRCa4y5ZsmSzRJFrbdW6desab8svWznnXBp/+xtcemmo14BwxnHOOXDVVdCqVflyLVvCww9D375w3HHw3/+GRJOhHj16UFZWRkU9buTu86gpTx7OOVed9evhV7+CW2+FJUtC2W67hYTxne9Uvl737vCnP8GRR8KIEfDHP0LKVk2F1LJlyxrfx1Edv2zlnHOVWbgQjj8e2raFX/4Sli2DI44IZx2vv1514sj52tdg1KiQRP7wh+LHXEc8eTjnXL7nnoN+/cKZw2OPhctR558fmt4+8wzstVe67V1+eagf+b//g5dfLk7MdcyTh3POAWzcGCq+t98eBg6EadOgVy+4++7Q5Pb3v4ett67dtps1g3HjQjI64QT46KPCxp4BTx7Ouabto4/g1FPDpamLL4YPP4TDDoOpU+Gdd+Csswqzn06d4JFH4IMP4OSTYcOG6tepxzx5OOeappdfhoMPhi98Ae6/P1Rkn3EGLF0K//53uGxVaCUlcMstMHFiqIBvwDx5OOeajo0b4fbbYccd4aCD4KWXoFs3uPlm+PRTGDMGOnQobgwjRsApp4QK+ImphymqN7yprnOu8VuxAi65JJxhrFoVzjJKSuB3vwuXqOqSBHfcAdOnh/6vXnklJLMGxs88nHON18yZ8NWvQseOcOed4X6N4cPh/fdhypS6Txw5bdvCo4/C2rXw7W+H5wbGk4dzrvF54AHYZRf40pdg8mTo3DnUMXz6abjf4gtfyDpC2H13GDs21L1cdFHW0aTml62cc+m9/z7cdVe45+GNN8LNc7lfzxneQQ2AWXgA7LMP/OY38I1vZBtTZYYNgx//GG68EQ49NJwVNRBFTx6SBgE3A82Bu83s2rz5vQhDz3YFlgInm1lZnLcjcDdhNEEDjjazdySNBfoDH8fNnG5m04t9LM41KR99FCqQ//EPmDcvtEJas6b8i7kizZqFR9b69QvNYhtCXcK114Z+r773Pdh3X+jTJ+uIaqSoyUNSc+A24OtAGTBF0gQzm5tY7AZgnJndJ2kgcA1wSpw3DrjazJ6R1A7YmFjv4jgKoXOutlauDDfB/f3voefXJUuqTxDNm4eb5XbYIVQ6n3RS6LKjhV/IqJWWLUO37X37hq5Q6kEHijVR7L/2gcD8OGwsksYDQ4Bk8ugD/DhOPwc8EZftA7Qws2cAzGxlkWN1rnFavTpcW58wAebMgcWLQ1l1ZxBt24ZmrH37hj6cBg/2BFEsO+wQunA/4gg4+2x48MHsL/9Vo9ifhO7Ae4nXZcCX85aZAQwjXNoaCrSX1BnYHVgu6XGgN/BP4DIzy92WebWknwOTYvma/J1LGgGMANixIZy+Oldbq1eHHlufeAJmzSpPEBs3Vr5Os2bQpk3ojmO//UK34Sec4AkiK1/9aqjUv+KKMA7ID3+YdURVqg+fkpHArZJOB54HFgAbCLEdDvQF/gc8BJwO3ANcDrwPtAJGA5cCo/I3bGaj43xKSkrSDZPlXH2zbh2MHh0ucbz6Knz8cSirSrNm0Lp1aF20774wdGiolE0x6I+rQ5deCi+8EFpfHXBAuJGxnip28lhAqOzO6RHLPmdmCwlnHsR6jePMbLmkMmB64pLXE8BBwD1mtiiuvkbSvYQE5FzDt25duJHtgQfCJaZly6pPEBDOFnbYIQx/OnhwuIO5tp34uezkOlDcf/9wFvjKK9C1a9ZRVajYyWMKsJuk3oSkMRz4bnIBSV2ApWa2kXBGMSaxbgdJXc1sMTAQKI3rdDOzRZIEHAvMLvJxOFc469aFEebuuy9cYlq6NJRVN4Z08+bQvj3svDN861vhskbnznUTs6s7HTuGGwgPOSQ0RnjqqfC3r2eKmjzMbL2k84GJhKa6Y8xsjqRRQKmZTQAGANdIMsJlq/PiuhskjQQmxSQxFbgrbvqPkroCAqYD3y/mcThXK088Ee6FmD49NHutaYLYemvYaScYNCiM/7D99nUQrKtX+vULXcCPGBEGkvrlL7OOaDPKHwi9sSopKbHS0tKsw3CNiVmof3joodB99+LF1TdzhXBpYuutoWfP0Lrmoosaxv0Irm6ZhV5+x42DJ58MPyYyIGmqmZXkl9eHCnPnGp7588MY1pXJNXXt0QMGDICRI0N3Gc7VlBSGrZ02rbwDxV69so7qc/XgVlDnGphHHilPHBLsumv4hThrVnnXGBs2wCefhFZRt9/uicPVTtu2YRjc9etDBfqaze5IyIyfeTiXxv/9H9x0U5ju0CG0hnKumHbdNdzkmesH67bbso4I8DMP52ruK18pTxxf/KInDld3hg4Nlz7/8Idw93k94MnDuZro3j0MTQqhq45Zs7KNxzU911wDhx8eui+ZMyfraDx5OFet1q1h4cIwfeONoQ8i5+paixahZV/79qErmU8+yTQcTx7OVWbp0tBqKldJ+cILoc7Duax06xZ+vLzxRujCPcNbLTx5OFeR558Pd2+bhRZVS5bAwQdnHZVzoen3r38dein4/e8zC8OTh3P5brgB+vcP023ahJ5pO3XKNibnki65JPRhdtFF8OKLmYTgycO5pOOPh4svDtM9e8KqVdnG41xFpNA32o47hvs/PvywzkPw5OFczp57hhuyAAYOhP/9L9t4nKtKhw6hA8WPPoLvfjfcmFqHPHk4B7DttmGcbghjKkyalG08ztVE377hpsFJk+DKK+t0136HuWva1q4tr9cA+POf4dhjMw3JuVTOOiu0BPzVr0KjjqOPrpPd+pmHa7rmzoWttipPHO++64nDNUy33hqGEj75ZHjnnTrZpScP1zQ99FAYdQ/CzVdr1ni36K7hatMm1H9s3FhnHSh68nBNz3nnhXG8ITTBXbcOWrXKNibnttQuu4QWWKWlcOGFRd9d0ZOHpEGS5kmaL+myCub3kjRJ0kxJkyX1SMzbUdLTkl6VNFfSTrG8t6SX4zYfkuT/+a5mDj00dC4HsO++4eY/5xqLIUPCPSB33AEPPFDUXRU1eUhqDtwGHAX0AU6U1CdvsRuAcWa2LzAKuCYxbxzwGzPbCzgQyDVmvg74nZntCiwDzireUbhGY/vtQ8UiwCmnwIwZ2cbjXDFcfXW4yXXECJg9u2i7KfaZx4HAfDN7y8zWAuOBIXnL9AGejdPP5ebHJNPCzJ4BMLOVZrYqjmc+EHg0rnMfcGxRj8I1bGvXhorxDz4Ir//whzC0p3ONUYsWof+rbbcNHSiuWFGU3RQ7eXQH3ku8LotlSTOAYXF6KNBeUmdgd2C5pMclTZP0m3gm0xlYbmbrq9imc8H774fEsXZteD1lCvzgB9nG5Fyxbb99aBTy5puhKW8ROlCscfKQtHusm5gdX+8r6acFiGEk0F/SNKA/sADYQLgH5fA4/wBgZ+D0NBuWNEJSqaTSxYsXFyBU16A8+2zohRRC77iffAIlJdnG5Fxd+cpXwhggzzwDb71V8M2nOfO4C7gcWAdgZjOB4dWsswDomXjdI5Z9zswWmtkwM+sL/CSWLSecUUyPl7zWA08A/YAlQAdJLSrbZmLbo82sxMxKunbtWtPjdI3B1VfD174Wptu2DV03tGuXbUzO1bWRI8P9TLvsUvBNp0kebc3sv3ll6ytcstwUYLfYOqoVIdlMSC4gqYukXByXA2MS63aQlPvWHwjMNTMj1I0cH8tPA/6S4jhcYzdkCPw0nhT36gWffpptPM5lRYIddijKptMkj48k7QJYiEnHA4uqWiGeMZwPTAReBR42szmSRkkaHBcbAMyT9DqwHXB1XHcD4ZLVJEmzABHOfgAuBX4saT6hDuSeFMfhGrPdd4cJ8ffJkUfW2d22zjU1shpWpEjaGRgNHEJoHvs2cJKZvVu88AqnpKTESktLsw7DFdM225QPzXnFFeHSlXNui0iaamabVRbWqGPE2MrpXDM7QtLWQDMzy3YAXedy8js3/Otf4Zhjso3JuUauRsnDzDZIOixO+wVkV3/MnVveRxWEzg29jyrnii5Nl+zTJE0AHgE+TyBm9njBo3KuJsaOhTPOCNMtW8LKld5HlXN1JE3yaE1oJjswUWaAJw9X977/fbjzzjDduXMYTc05V2dqnDzM7IxiBuJcjVxxBVx/ffmQm337wiuvZBuTc01QmjvMe0j6s6QP4+OxZA+4zhXN3/8ebvSTwh2zucQxbJgnDucykuY+j3sJN/jtEB9/jWXOFV5ZGWy3XUgYxxwDn31WPm/w4NBXz2OPZRefc01cmuTR1czuNbP18TEW8D4/XOGsWQMHHBASRs+e8OGH5fP22ANWrw5J4y/eoYBzWUuTPJZIOllS8/g4mVCB7tyWOfNMaN4cWrcOo6DldOwI06aFhPHaa6F3XOdcvZAmeZwJfBt4n9AtyfGAV6K72rnnnpAMJLj33vIb/Fq1grvvDglj6VLYb79Mw3TOVSxNa6t3gcHVLuhcZaZPh4EDYdmyTcubNYPTToMxYypczTlX/6RpbXWfpA6J1x0l+X+7q9qaNbDnnuEMo2/fTRNHSUmox9iwwROHcw1MmstW+8ZxNgAws2VA34JH5BqHIUNCwmjdGubNKy/ffnt4771wWWrKFK/HcK6BSpM8mknqmHshqRPp7lB3jd2vfx3GT5bKu0WHcI/G44+HhLFoEfTw24Oca+jSfPn/FnhR0iOEsTWOJ4694Zqw554L912sXLlpefPmcNFFcN112cTlnCuqNBXm4ySVUt631TAzm1ucsFy9tngx9OsXbuTLN3AgTJpU9zE55+pUjZNHHEXwTTObK2kAcISkhcl6ENfIDRmy6eWonJ12ghkzwmBMzrkmIU2dx2PABkm7AncCPYEHq1tJ0iBJ8yTNl3RZBfN7SZokaaakycn+siRtkDQ9PiYkysdKejsxb78Ux+HSWL26vJuQZOLYZhv4979DPcbbb3vicK6JSZM8NsYxyYcBt5rZxUC3qlaIIxDeBhwF9AFOlNQnb7EbgHFmti8wCrgmMe8zM9svPvLvMbk4MW96iuNwNTFpUhgjo02bTbsJOfvskDA+/hgOOyy7+JxzmUqTPNZJOhE4FfhbLGtZzToHAvPN7C0zWwuMB4bkLdMHeDZOP1fBfFeXzjornGUccQSsXx/KWrQoP8sYPTrb+Jxz9UKa5HEGcDBwtZm9Lak3cH8163QH3ku8LotlSTMIZzMAQ4H2kjrH160llUp6SdKxeetdHS91/U5ShTcLSBoR1y9dvHhxNaE2YatXQ69eIWkkb9bbfvvQm+26dX6W4ZzbRI2Th5nNNbMfmdmf4uu3zezzdpiSats/9kigv6RpQH9gARAHbKCXmZUA3wVuipX2AJcDewIHAJ2ASyuJebSZlZhZSdeu3gHwZqZPDzfptWkD//tfefnxx5ffk9G6dWbhOefqrzRnHtXZuYKyBYSK9ZwesexzZrbQzIaZWV/gJ7FseXxeEJ/fAiYT72g3s0UWrCGMKXJgAY+j8bvkktCfVN++sHZtKGvWDB59NCSNRx7JNj7nXL1XyDvErYKyKcBu8RLXAmA44Szic5K6AEvNbCPhjGJMLO8IrDKzNXGZQ4Hr47xuZrZIkoBjgdkFPI7Ga++9YW7erTmdOsGbb0KHDpmE5JxrmAp55rGZ2DrrfGAi8CrwsJnNkTRKUq711ABgnqTXge0ov2t9L6BU0gxCRfq1iZsS/yhpFjAL6AL8qpjH0aC98075EK7JxDFwYDjLWLLEE4dzLjWZVXTCUIsNSdPipad6qaSkxEqTAw01djfcEC5PJf++Etx5Z2hu65xzNSBpaqx73kSaO8y/Bfw9Xl6qSIWV1q6OHXIIvPjipmVbbw3z54fWU845VwBpLlt9B3hD0vWS9syfaWZPFy4sl8ry5bDttuHMIpk4+vULZx4rV3ricM4VVJqmuicTWju9CYyV9GK8j6J90aJzVRs7NrSS6tgRVqwIZRL88pchaUydmml4zrnGK1VrKzNbIelRoA1wIeGmvosl3WJmvy9CfK4iRx8NTz21adlWW4X7Nvbc7KTQOecKLk2dx2DCXea7AuOAA83sQ0ltgbmAJ49iWrUKevaEpUs3Ld99901H6nPOuTqQ5szjOOB3ZvZ8stDMVkk6q7BhuU0sXQqdO29a9sMfwi23ZBOPc67JS5M8rgQW5V5IagNsZ2bvmJmP/lNMJYlWci+/DAf6DfXOuWylaW31CJBsprshlrlie/vt8PyjH3nicM7VC2mSR4vYrToAcbpV4UNylbr55qwjcM45IF3yWJzoUgRJQ4CPCh+S28Slfu+lc67+SVPn8X1Cn1K3AiKM03FqUaJy5W68MTz36FH1cs45V4dqnDzM7E3gIEnt4uuVRYvKlcuN5jdjRrZxOOdcQqqbBCV9E9ibMMIfAGY2qghxOYAFiaFPOnXKLg7nnMtT4zoPSXcQ+rf6IeGy1QlAryLF5QAOOCA8tyjksCvOObfl0lSYH2JmpwLLzOyXhPHMdy9OWA4Iw8AC/Oxn2cbhnHN50iSP1fF5laQdgHVAt8KH5Dbz859nHYFzzm0iTfL4q6QOwG+AV4B3gAerW0nSIEnzJM2XdFkF83tJmiRppqTJknok5m2QND0+JiTKe0t6OW7zIUmN736T887LOgLnnKtUjZKHpGbAJDNbbmaPEeo69jSzKn8SS2oO3AYcBfQBTpTUJ2+xG4BxZrYvMAq4JjHvMzPbLz4GJ8qvI/SztSuwDGh8fWvdeWd43t2vDDrn6p8aJY84euBtiddrzOzjGqx6IDDfzN6Kd6SPB4bkLdMHeDZOP1fB/E0oNPMaCDwai+4Djq1BLA3Lhg3hefr0TMNwzrmKpLlsNUnSccq10a2Z7oSbCXPKYlnSDGBYnB4KtJeU60K2taRSSS9JOjaWdQaWm9n6KrYJQBysqlRS6eLFi1OEnbH588un27TJLg7nnKtEmuRxDqEjxDWSVkj6RNKKAsQwEugvaRrQH1hA6HQRoFcceP27wE2SdkmzYTMbbWYlZlbStWvXAoRaRw46KDy3anxVOc65xiHNHea1GW52AdAz8bpHLEtudyHxzCPevX6cmS2P8xbE57ckTSYMg/sY0EFSi3j2sdk2G7wlS8Lz9ddnG4dzzlUizUiCX6moPH9wqDxTgN0k9SZ8wQ8nnEUkt9sFWBrrVS4HxsTyjsAqM1sTlzkUuN7MTNJzwPGEOpTTgL/U9DgalAsuyDoC55yrUJpbly9OTLcmVIZPJVReV8jM1ks6H5gINAfGmNkcSaOAUjObAAwArpFkwPNAro3qXsCdkjYSLq9da2Zz47xLgfGSfgVMA+5JcRz12/DhWUfgnHPVkpnVbkWpJ3CTmR1X2JCKo6SkxEpLS7MOo3rNmoEZfOlL3tLKOZc5SVNj3fMm0lSY5ysjnB24Qsol8xdfzDYO55yrQpo6j98DudOUZsB+hDvNXaFMmVI+7U10nXP1WJo6j+Q1n/XAn8zsPwWOp2k78sjw7InDOVfPpUkejwKrzWwDhK5HJLU1s1XFCa0JWr48PN97b6ZhOOdcdVLdYQ4kfxK3Af5Z2HAcAN/5TtYROOdcldIkj9bJoWfjdNvCh9REDRqUdQTOOVdjaZLHp5L65V5I2h/4rPAhNVFPPx2eDz442zicc64G0tR5XAg8ImkhYRja7QnD0rpCyDXRnTQp2zicc64G0vRtNUXSnsAesWiema0rTlhNzJNPlk97SyvnXANQ48tWks4Dtjaz2WY2G2gn6dzihdaE5CrI27XLNg7nnKuhNHUeZ+d6uwUws2XA2QWPqClaGdshPPRQtnE451wNpUkezZMDQcUhZn3AiS31WaLNwdFHZxeHc86lkKbC/B/AQ5Li4NqcE8vclvja18JzqgEanXMuW2mSx6WEhPGD+PoZ4O6CR9TU5DpAzHVN4pxzDUCa1lYbgdvjwxXaP/wkzjnXcKTpVXc34BqgD2EwKADMbOcixNU0jB+fdQTOOVcraSrM7yWcdawHvgqMAx6obiVJgyTNkzRf0mUVzO8laZKkmZImS+qRN38bSWWSbk2UTY7bnB4fX0hxHPXHmWeG5223zTYO55xLKU3yaGNmkwijD75rZlcC36xqhdgi6zbgKMIZy4mS+uQtdgMwzsz2BUYRzm6SriIMT5vvJDPbLz4+THEc9UeupdXf/55tHM45l1Ka5LFGUjPgDUnnSxoKVHdX24HAfDN7y8zWAuOBIXnL9AGejdPPJefH/rO2A55OEWfDkGyie+ih2cXhnHO1kCZ5XEDoRfdHwP7AycBp1azTHXgv8bosliXNAIbF6aFAe0mdY6L6LTCykm3fGy9Z/Sx5/0mSpBGSSiWVLl68uJpQ61iuA0Rvouuca4BqnDzMbIqZrTSzMjM7w8yOM7OXChDDSKC/pGlAf2ABsAE4F3jSzMoqWOckM9sHODw+Tqkk5tFmVmJmJV27di1AqAU0Y0Z4/va3s43DOedqIc19HpuRNMLMRlexyAKgZ+J1j1j2OTNbSDzzkNQOOM7Mlks6GDg89p/VDmglaaWZXWZmC+K6n0h6kHB5bNyWHEtmvMWVc64B2qLkQeiavSpTgN0k9SYkjeHAdzfZgNQFWBrvI7kcGANgZiclljkdKDGzyyS1ADqY2UeSWgLH0NBGNLz55qwjcM65LZKmzmMzZnZnNfPXA+cDE4FXgYfNbI6kUZIGx8UGAPMkvU6oHL+6mt1uBUyUNBOYTkhKd9X6ILJwySXhuXPnbONwzrlakuUGIapuQekCwr0enxC6JekLXGZmDaIlVElJiZWWlmYdRpCrJH/jDdh112xjcc65KkiaamYl+eVpzjzONLMVwJFAR0Il9bUFiq/pSDbR9cThnGug0iSPXP3G0cD9ZjaH6us8XL4vfSk8N2+ebRzOObcF0iSPqZKeJiSPiZLaAxuLE1Yj9sYb4fmcc7KNwznntkCa1lZnAfsBb5nZKkmdgTOKElVTcNttWUfgnHO1lubMYwjwZmIo2g2A96ibxqhRWUfgnHMFkSZ5/MLMPs69iEnkFwWPqDG76qrw3K1btnE459wWSpM8Klp2S28ybFrWrw/PU6ZkG4dzzm2hNMmjVNKNknaJjxuBqcUKrNFZurR8unt+35DOOdewpEkePwTWAg/FxxrgvGIE1Sjlmui28JM151zDl2YM80+BzUYCdDVUFjsHvvzybONwzrkCqDZ5SLrJzC6U9Fdgs75MzGxwBau5yniLK+dcI1CTM4/74/MNxQykUfvRj7KOwDnnCqra5GFmU+NY5COS3aS7FP7wh/Dcu3e2cTjnXIHUqMLczDYAvSS1KnI8jdOGDeG5vvTq65xzWyhN05+3gP9ImgB8mis0sxsLHlVjMn9++XSnTtnF4ZxzBZQmebwZH82A9rGsZoOBNGWHHhqeW/lJm3Ou8UiTPOaa2SPJAkknVLeSpEHAzUBz4G4zuzZvfi/C0LNdgaXAyWZWlpi/DTAXeMLMzo9l+wNjgTbAk8AFVtNRrerahx+G56urGyDROecajjQ3CVZ0g0KVNy3EivbbgKOAPsCJkvrkLXYDMM7M9gVGAdfkzb8KeD6v7HbgbGC3+BhUkwPI1MiRWUfgnHMFU5P7PI4ijOHRXdItiVnbAOurWf1AYL6ZvRW3NZ7QO+/cxDJ9gB/H6eeAJxL73p8wrvk/gJJY1g3Yxsxeiq/HAccCT1V3LHXuJG+c5pxrnGpy5rEQKAVWE/qyyj0mAN+oZt3uwHuJ12WxLGkGMCxODwXaS+osqRnwWyD/J3v3uJ2qtlk/jB8fnvvkn2w551zDVpP7PGYAMyQ9GJff0czmFTCGkcCtkk4nXJ5aQBgr5FzgSTMrk2o32q2kEcAIgB133LEgwaayMQ606E10nXONTJoK80GE+olWQG9J+wGjqumeZAHQM/G6Ryz7nJktJJ55SGoHHGdmyyUdDBwu6VygHdBK0kpC5XuPqraZ2PZoYDRASUlJ3Vaoz5xZPt2mTZ3u2jnnii1NhfmVhDqM5QBmNh2o7pbpKcBuknrHGwyHEy53fU5Sl3iJCkIF/Ji4/ZPMbEcz24lwdjLOzC4zs0XACkkHKZySnAr8JcVx1I0BA8LzVltlGoZzzhVDmuSxLjmSYFTlr3kzWw+cD0wEXgUeNrM5kkZJyp2xDADmSXqdUDlekzat5wJ3A/MJ957Uv8ryZcvC8113ZRuHc84VgWp6e4Ske4BJhG7ZjwN+BLQ0s+8XL7zCKSkpsdK6rHvI1dPU09tPnHOuJiRNNbOS/PK0g0HtTRgE6kHgY+CCwoTXyAz2Xuqdc41bmuTRJz5aAK0J92v4YNwV+dvfwvMBB2Qbh3POFUma1lZ/JFRczwY2FiecRiJ3qepf/8o2DuecK5I0yWOxmf21aJE0FpMmlU97E13nXCOVJnn8QtLdhErzNblCM3u84FE1ZEOHhue2bbONwznniihN8jgD2BNoSfllKwM8eSR98kl4fuCBbONwzrkiSpM8DjCzPYoWSWOTOwNxzrlGKE1rqxcq6E7dJfXvH55r2ReXc841FGnOPA4Cpkt6m1DnIcDiOBwO4N//Ds8DB2Ybh3POFVnajhFdVXJNdP/5z2zjcM65Iqtx8jCzd4sZSIP35z9nHYFzztWZNHUeriq5UQPbt882DuecqwOePArls8/C85NPZhuHc87VAU8ehZBLHACHHZZdHM45V0c8eRTC4YeHZ2+i65xrIjx5FMLUqeH52GMzDcM55+qKJ49Cetx7anHONQ1FTx6SBkmaJ2m+pMsqmN9L0iRJMyVNltQjUf6KpOmS5kj6fmKdyXGb0+PjC8U+jkrdfntmu3bOuaykuUkwNUnNgduArwNlwBRJE8xsbmKxG4BxZnafpIHANcApwCLgYDNbI6kdMDuuuzCud5KZ1eG4spW48MLw3KlTpmE451xdKvaZx4HAfDN7y8zWAuMJIxAm9QGejdPP5eab2Vozy3X9vlUdxFo7a9eG58mTMw3DOefqUrG/kLsD7yVel8WypBnAsDg9FGgvqTOApJ6SZsZtXJc46wC4N16y+plUcTMnSSMklUoqXbx4cSGOZ1PJJrr77FP47TvnXD1VH37NjwT6S5oG9AcWABsAzOy92PHirsBpkraL65xkZvsAh8fHKRVt2MxGm1mJmZV07dq18JH36xeem9WHt9E55+pOsb/1FgA9E697xLLPmdlCMxtmZn2Bn8Sy5fnLEMZOPzy+XhCfPwEeJFweq3uvvRaeTz89k90751xWip08pgC7SeotqRUwHJiQXEBSF0m5OC4HxsTyHpLaxOmOwGHAPEktJHWJ5S2BYwiJJTv33JPp7p1zrq4VNXmY2XrgfGAi8CrwsJnNkTRK0uC42ABCUngd2A64OpbvBbwsaQbwL+AGM5tFqDyfGOtCphPOZO4q5nFU6Npr63yXzjlXX8hyY1A0ciUlJVZaWsCWva1awbp1sN128P77hduuc87VI5KmmllJfrnX9NbWunXhOdc1iXPONSGePGpj6dLy6e75LY+dc67x8+RRG7kmus2bZxuHc85lxJNHbbwbR+S94IJs43DOuYx48tgSv/1t1hE451wmPHmkdemlWUfgnHOZ8+SRVu5so1evbONwzrkMefJIa8OG8PzKK9nG4ZxzGfLkkcaCRLdcPn6Hc64J8+SRRkm8ybJFUcfQcs65es+TRxq5bkiuuirbOJxzLmOePGrjss2GYnfOuSbFk0dNnXVW1hE451y94cmjpsaODc977JFpGM45Vx948qipjRvD87Rp2cbhnHP1gCePmpg1q3y6TZvs4nDOuXqi6MlD0iBJ8yTNl7RZTbOkXpImSZopabKkHonyVyRNlzRH0vcT6+wvaVbc5i2SVNSDGDAgPLdqVdTdOOdcQ1HU5CGpOXAbcBTQBzhRUp+8xW4AxpnZvsAo4JpYvgg42Mz2A74MXCZphzjvduBsYLf4GFTM4/h8/I6bbirqbpxzrqEo9pnHgcB8M3vLzNYC44Ehecv0AZ6N08/l5pvZWjNbE8u3ysUqqRuwjZm9ZGEM3XHAsUU9ipwf/KBOduOcc/VdsZNHd+C9xOuyWJY0AxgWp4cC7SV1BpDUU9LMuI3rzGxhXL+smm0S1x8hqVRS6eLFi2t3BCecULv1nHOuEasPFeYjgf6SpgH9gQXABgAzey9eztoVOE3Sdmk2bGajzazEzEq6du1au+geeyw877df7dZ3zrlGqNidNC0AeiZe94hln4tnE8MAJLUDjjOz5fnLSJoNHA78J26n0m0WlFl4fuGFou3COecammKfeUwBdpPUW1IrYDgwIbmApC6ScnFcDoyJ5T0ktYnTHYHDgHlmtghYIemg2MrqVOAvRT4Ob6LrnHMJRU0eZrYeOB+YCLwKPGxmcySNkjQ4LjYAmCfpdWA74OpYvhfwsqQZwL+AG8wsd8PFucDdwHzgTeCpIh5E+dmHc845AGRN5IuxpKTESktLsw7DOecaFElTzawkv7w+VJg755xrYDx5OOecS82Th3POudQ8eTjnnEvNk4dzzrnUPHk455xLzZOHc8651JrMfR6SFgPvZh1HFboAH2UdRA01lFg9zsJqKHFCw4m1IcTZy8w26xywySSP+k5SaUU34tRHDSVWj7OwGkqc0HBibShxVsQvWznnnEvNk4dzzrnUPHnUH6OzDiCFhhKrx1lYDSVOaDixNpQ4N+N1Hs4551LzMw/nnHOpefJwzjmXmiePIpHUU9JzkuZKmiPpglh+paQFkqbHx9GJdS6XNF/SPEnfSJQPimXzJV1WpHjfkTQrxlQayzpJekbSG/G5YyyXpFtiPDMl9Uts57S4/BuSTitwjHsk3rfpklZIurC+vKeSxkj6MA6ZnCsr2Hsoaf/4N5of11UB4/yNpNdiLH+W1CGW7yTps8R7e0d18VR2zAWKs2B/a4URTl+O5Q8pjHZaqDgfSsT4jqTpsTyz97PgzMwfRXgA3YB+cbo98DrQB7gSGFnB8n2AGcBWQG/CCInN4+NNYGegVVymTxHifQfokld2PXBZnL4MuC5OH00YvVHAQcDLsbwT8FZ87hinOxbp/W0OvA/0qi/vKfAVoB8wuxjvIfDfuKziukcVMM4jgRZx+rpEnDsll8vbToXxVHbMBYqzYH9r4GFgeJy+A/hBoeLMm/9b4OdZv5+FfviZR5GY2SIzeyVOf0IYhrd7FasMAcab2Roze5swxO6B8THfzN4ys7XA+LhsXRgC3Ben7wOOTZSPs+AloIOkbsA3gGfMbKmZLQOeAQYVKbavAW+aWVW9BtTpe2pmzwNLK4hhi9/DOG8bM3vJwrfIuMS2tjhOM3vawrDRAC8BParaRjXxVHbMWxxnFVL9reOv+oHAo8WMM+7n28CfqtpGXbyfhebJow5I2gnoC7wci86PlwfGJE5BuwPvJVYri2WVlReaAU9LmippRCzbzswWxen3CWPM14dYAYaz6T9kfXxPoXDvYfc4nV9eDGcSfvnm9JY0TdK/JB0ey6qKp7JjLpRC/K07A8sTCbNY7+fhwAdm9kairL69n7XiyaPIJLUDHgMuNLMVwO3ALsB+wCLCKW19cJiZ9QOOAs6T9JXkzPhrqF60647XpgcDj8Si+vqebqI+vYeVkfQTYD3wx1i0CNjRzPoCPwYelLRNTbdXhGNuEH/rhBPZ9EdOfXs/a82TRxFJaklIHH80s8cBzOwDM9tgZhuBuwin1QALgJ6J1XvEssrKC8rMFsTnD4E/x7g+iKfTudPqD+tDrIQE94qZfRBjrpfvaVSo93ABm15KKnjMkk4HjgFOil9SxMtAS+L0VEL9we7VxFPZMW+xAv6tlxAuFbaoIP6CiNseBjyUiL9evZ9bwpNHkcRrnfcAr5rZjYnybonFhgK5FhoTgOGStpLUG9iNUIE2BdgttgxpRbhcM6HAsW4tqX1umlB5OjvuJ9fa5zTgL4lYT1VwEPBxPK2eCBwpqWO8nHBkLCu0TX7N1cf3NKEg72Gct0LSQfGzdWpiW1tM0iDgEmCwma1KlHeV1DxO70x4D9+qJp7KjrkQcRbkbx2T43PA8cWIMzoCeM3MPr8cVd/ezy2SdY19Y30AhxFOL2cC0+PjaOB+YFYsnwB0S6zzE8IvkXkkWtLE9V6P835ShFh3JrRCmQHMye2DcF14EvAG8E+gUywXcFuMZxZQktjWmYTKyvnAGUWIdWvCr8ZtE2X14j0lJLRFwDrCNeuzCvkeAiWEL8s3gVuJPUQUKM75hLqB3Gf1jrjscfEzMR14BfhWdfFUdswFirNgf+v4uf9vPPZHgK0KFWcsHwt8P2/ZzN7PQj+8exLnnHOp+WUr55xzqXnycM45l5onD+ecc6l58nDOOZeaJw/nnHOpefJwzjmXmicP5+pAvHntn7Eb7u/UYv1jJfUpRmzO1UaL6hdxzhVAXwAz26+W6x8L/A2YW9MVJLWw8o7/nCsoP/NwTVocnOc1SWMlvS7pj5KOkPSfOPjOgfHxYuwJ9QVJe8R1/0/SmDi9j6TZktpWsI8vAA8AB8Qzj10UBv75V+zFeGKi76KzJU2RNEPSY5LaSjqE0BHkbxLrT5ZUEtfpIumdOH26pAmSngUmxa5nxkj6b4x/SFxu71g2XaGH2t2K/267RiXrW9z94Y8sH4TBedYD+xB+TE0FxhC6DxkCPAFsQ/lASUcAj8XpZsDzhD6WSoFDq9jPAOBvcbol8ALQNb7+DjAmTndOrPMr4IdxeixwfGLeZGKXJkAX4J04fTqhi4xcNyi/Bk6O0x0I3XRsDfye0AEihEGS2mT9t/BHw3r4ZSvn4G0zmwUgaQ4wycxM0ixCctkWuC/+OjfClz9mtjH2RDsTuNPM/lPD/e0BfBF4JvSBR3NC30gAX5T0K8IXfTtq17HkM2aWG5zoSGCwpJHxdWtgR+BF4CeSegCP26bjTThXLU8ezsGaxPTGxOuNhP+Rq4DnzGyowsBekxPL7wasBHZIsT8Bc8zs4ArmjQWONbMZMTENqGQb6ym/7Nw6b96nefs6zszm5S3zqqSXgW8CT0o6x8yerfkhuKbO6zycq962lI+tcHquUNK2wC2EMaw7Szp+81UrNA/oKunguJ2WkvaO89oDixTGgjkpsc4ncV7OO8D+cbqq/U4Efhi7+UZS3/i8M6Er8FsIXXzvW8PYnQM8eThXE9cD10iaxqZn678DbjOz1wndhV8bK8erZGEs7eOB6yTNIHTPfUic/TPCcMX/AV5LrDYeuDhWeu8C3AD8IMbUpYrdXUW4zDYzXpK7KpZ/G5gtaTrhEtq46uJ2Lsm7ZHfOOZean3k455xLzSvMnSsgSWcAF+QV/8fMzssiHueKxS9bOeecS80vWznnnEvNk4dzzrnUPHk455xLzZOHc8651P4/Sc/cR80arKAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_diffrent_max_features():\n",
    "    global max_features\n",
    "    a=[]\n",
    "    b=[]\n",
    "    for i in range(1000,20000,2000):\n",
    "        max_features=i\n",
    "        print(\"max_features=%d\" % i)\n",
    "        x, y = get_features_by_wordbag()\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=0)\n",
    "        gnb = GaussianNB()\n",
    "        gnb.fit(x_train, y_train)\n",
    "        y_pred = gnb.predict(x_test)\n",
    "        score=metrics.accuracy_score(y_test, y_pred)\n",
    "        a.append(max_features)\n",
    "        b.append(score)\n",
    "        plt.plot(a, b, 'r')\n",
    "    plt.xlabel(\"max_features\")\n",
    "    plt.ylabel(\"metrics.accuracy_score\")\n",
    "    plt.title(\"metrics.accuracy_score VS max_features\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "show_diffrent_max_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ../Data/mail/enron1/ham/\n",
      "Load ../Data/mail/enron1/spam/\n",
      "CountVectorizer(binary=True, decode_error='ignore', max_features=19000,\n",
      "                stop_words='english', strip_accents='ascii')\n",
      "TfidfTransformer(smooth_idf=False)\n"
     ]
    }
   ],
   "source": [
    "x,y=get_features_by_wordbag_tfidf()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4, random_state = 0)\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train,y_train)\n",
    "y_pred=gnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972933784436926"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1439,   24],\n",
       "       [  32,  574]], dtype=int64)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.2　支持向量机算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_svm_wordbag(x_train, x_test, y_train, y_test):\n",
    "    print(\"SVM and wordbag\")\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM and wordbag\n",
      "Load ../Data/mail/enron1/ham/\n",
      "Load ../Data/mail/enron1/spam/\n",
      "CountVectorizer(decode_error='ignore', max_features=19000, stop_words='english',\n",
      "                strip_accents='ascii')\n",
      "0.9739004349927501\n",
      "[[1429   34]\n",
      " [  20  586]]\n"
     ]
    }
   ],
   "source": [
    "x,y = get_features_by_wordbag()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4, random_state = 0)\n",
    "\n",
    "do_svm_wordbag(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM and wordbag\n",
      "Load ../Data/mail/enron1/ham/\n",
      "Load ../Data/mail/enron1/spam/\n",
      "CountVectorizer(binary=True, decode_error='ignore', max_features=19000,\n",
      "                stop_words='english', strip_accents='ascii')\n",
      "TfidfTransformer(smooth_idf=False)\n",
      "0.9908168197196714\n",
      "[[1451   12]\n",
      " [   7  599]]\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM and wordbag\")\n",
    "x,y = get_features_by_wordbag_tfidf()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4, random_state = 0)\n",
    "\n",
    "do_svm_wordbag(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.3　深度学习算法之MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_dnn_wordbag(x_train, x_test, y_train, y_test):\n",
    "    print(\"DNN and wordbag\")\n",
    "\n",
    "    # Building deep neural network\n",
    "    clf = MLPClassifier(solver='lbfgs',\n",
    "                        alpha=1e-5,\n",
    "                        hidden_layer_sizes = (5, 2),\n",
    "                        random_state = 1)\n",
    "    print( clf)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ../Data/mail/enron1/ham/\n",
      "Load ../Data/mail/enron1/spam/\n",
      "CountVectorizer(decode_error='ignore', max_features=19000, stop_words='english',\n",
      "                strip_accents='ascii')\n",
      "DNN and wordbag\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
      "              solver='lbfgs')\n",
      "0.9811503141614306\n",
      "[[1446   17]\n",
      " [  22  584]]\n"
     ]
    }
   ],
   "source": [
    "x,y = get_features_by_wordbag()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4, random_state = 0)\n",
    "do_dnn_wordbag(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ../Data/mail/enron1/ham/\n",
      "Load ../Data/mail/enron1/spam/\n",
      "CountVectorizer(binary=True, decode_error='ignore', max_features=19000,\n",
      "                stop_words='english', strip_accents='ascii')\n",
      "TfidfTransformer(smooth_idf=False)\n",
      "DNN and wordbag\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
      "              solver='lbfgs')\n",
      "0.7071048815853069\n",
      "[[1463    0]\n",
      " [ 606    0]]\n"
     ]
    }
   ],
   "source": [
    "x,y = get_features_by_wordbag_tfidf()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4, random_state = 0)\n",
    "do_dnn_wordbag(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.4　深度学习算法之CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cnn_wordbag(trainX, testX, trainY, testY):\n",
    "    global max_document_length\n",
    "    print(\"CNN and tf\")\n",
    "\n",
    "    trainX = pad_sequences(trainX, maxlen=max_document_length, value=0.)\n",
    "    testX = pad_sequences(testX, maxlen=max_document_length, value=0.)\n",
    "    # Converting labels to binary vectors\n",
    "    trainY = to_categorical(trainY, nb_classes=2)\n",
    "    testY = to_categorical(testY, nb_classes=2)\n",
    "\n",
    "    # Building convolutional network\n",
    "    network = input_data(shape=[None,max_document_length], name='input')\n",
    "    network = tflearn.embedding(network, input_dim=1000000, output_dim=128)\n",
    "    branch1 = conv_1d(network, 128, 3, padding='valid', activation='relu', regularizer=\"L2\")\n",
    "    branch2 = conv_1d(network, 128, 4, padding='valid', activation='relu', regularizer=\"L2\")\n",
    "    branch3 = conv_1d(network, 128, 5, padding='valid', activation='relu', regularizer=\"L2\")\n",
    "    network = merge([branch1, branch2, branch3], mode='concat', axis=1)\n",
    "    network = tf.expand_dims(network, 2)\n",
    "    network = global_max_pool(network)\n",
    "    network = dropout(network, 0.8)\n",
    "    network = fully_connected(network, 2, activation='softmax')\n",
    "    network = regression(network, optimizer='adam', learning_rate=0.001,\n",
    "                         loss='categorical_crossentropy', name='target')\n",
    "    # Training\n",
    "    model = tflearn.DNN(network, tensorboard_verbose=0)\n",
    "    model.fit(trainX, trainY,\n",
    "              n_epoch=5, shuffle=True, validation_set=(testX, testY),\n",
    "              show_metric=True, batch_size=100,run_id=\"spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m0.59738\u001b[0m\u001b[0m | time: 35.088s\n",
      "| Adam | epoch: 005 | loss: 0.59738 - acc: 0.7185 -- iter: 3100/3103\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m0.59925\u001b[0m\u001b[0m | time: 37.318s\n",
      "| Adam | epoch: 005 | loss: 0.59925 - acc: 0.7166 | val_loss: 0.60480 - val_acc: 0.7071 -- iter: 3103/3103\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "x,y = get_features_by_wordbag()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4, random_state = 0)\n",
    "do_cnn_wordbag(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18990</th>\n",
       "      <th>18991</th>\n",
       "      <th>18992</th>\n",
       "      <th>18993</th>\n",
       "      <th>18994</th>\n",
       "      <th>18995</th>\n",
       "      <th>18996</th>\n",
       "      <th>18997</th>\n",
       "      <th>18998</th>\n",
       "      <th>18999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3103 rows × 19000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2      3      4      5      6      7      8      9      \\\n",
       "0         0      1      0      0      0      0      0      0      0      0   \n",
       "1         0      0      0      0      0      0      0      0      0      0   \n",
       "2         0      0      0      0      0      0      0      0      0      0   \n",
       "3         0      0      0      0      0      0      0      0      0      0   \n",
       "4         0      0      0      0      0      0      0      0      0      0   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3098      0      0      0      0      0      0      0      0      0      0   \n",
       "3099      0      2      0      0      0      0      0      0      0      0   \n",
       "3100      0      0      0      0      0      0      0      0      0      0   \n",
       "3101      0      1      0      0      0      0      0      0      0      0   \n",
       "3102      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "      ...  18990  18991  18992  18993  18994  18995  18996  18997  18998  \\\n",
       "0     ...      0      0      0      0      0      0      0      0      0   \n",
       "1     ...      0      0      0      0      0      0      0      0      0   \n",
       "2     ...      0      0      0      0      0      0      0      0      0   \n",
       "3     ...      0      0      0      0      0      0      0      0      0   \n",
       "4     ...      0      0      0      0      0      0      0      0      0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3098  ...      0      0      0      0      0      0      0      0      0   \n",
       "3099  ...      0      0      0      0      0      0      0      0      0   \n",
       "3100  ...      0      0      0      0      0      0      0      0      0   \n",
       "3101  ...      0      0      0      0      0      0      0      0      0   \n",
       "3102  ...      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "      18999  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "3098      0  \n",
       "3099      0  \n",
       "3100      0  \n",
       "3101      0  \n",
       "3102      0  \n",
       "\n",
       "[3103 rows x 19000 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3103 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9   ...  90  91  92  93  94  95  96  \\\n",
       "0      0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "1      0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "2      0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "3      0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "4      0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "3098   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "3099   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "3100   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "3101   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "3102   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "      97  98  99  \n",
       "0      0   0   0  \n",
       "1      0   0   0  \n",
       "2      0   0   0  \n",
       "3      0   0   0  \n",
       "4      0   0   0  \n",
       "...   ..  ..  ..  \n",
       "3098   0   0   0  \n",
       "3099   0   0   0  \n",
       "3100   0   0   0  \n",
       "3101   0   0   0  \n",
       "3102   0   0   0  \n",
       "\n",
       "[3103 rows x 100 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = pad_sequences(x_train, maxlen=max_document_length, value=0.)\n",
    "pd.DataFrame(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.5　深度学习算法之RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_rnn_wordbag(trainX, testX, trainY, testY):\n",
    "    global max_document_length\n",
    "    print(\"RNN and wordbag\")\n",
    "\n",
    "    trainX = pad_sequences(trainX, maxlen=max_document_length, value=0)\n",
    "    testX = pad_sequences(testX, maxlen=max_document_length, value=0)\n",
    "    # Converting labels to binary vectors\n",
    "    trainY = to_categorical(trainY, nb_classes=2)\n",
    "    testY = to_categorical(testY, nb_classes=2)\n",
    "\n",
    "    # Network building\n",
    "    net = tflearn.input_data([None, max_document_length])\n",
    "    net = tflearn.embedding(net, input_dim=5000, output_dim=128)\n",
    "    net = tflearn.lstm(net, 128, dropout=0.8)\n",
    "    net = tflearn.fully_connected(net, 2, activation='softmax')\n",
    "    net = tflearn.regression(net, optimizer='adam', learning_rate=0.001,\n",
    "                             loss='categorical_crossentropy')\n",
    "\n",
    "    # Training\n",
    "    model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "    model.fit(trainX, trainY, validation_set=(testX, testY), show_metric=True,\n",
    "              batch_size=10,run_id=\"spm-run\",n_epoch=5)\n",
    "# 获取特征\n",
    "x, y = get_features_by_wordbag()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=0)\n",
    "\n",
    "do_rnn_wordbag(x_train, x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ../Data/mail/enron1/ham/\n",
      "Load ../Data/mail/enron1/spam/\n",
      "WARNING:tensorflow:From d:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\initializers_v1.py:59: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic Tensor (lstm_6/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-09f1fc9908e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0mdo_rnn_wordbag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-09f1fc9908e6>\u001b[0m in \u001b[0;36mdo_rnn_wordbag\u001b[1;34m(trainX, testX, trainY, testY)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     ])\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0mlayers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    219\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    774\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m               \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 776\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m     \u001b[1;31m# LSTM does not support constants. Ignore it during process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1108\u001b[1;33m     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(self, inputs, initial_state, constants)\u001b[0m\n\u001b[0;32m    856\u001b[0m         \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m       \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mget_initial_state_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m       init_state = get_initial_state_fn(\n\u001b[1;32m--> 642\u001b[1;33m           inputs=None, batch_size=batch_size, dtype=dtype)\n\u001b[0m\u001b[0;32m    643\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m       init_state = _generate_zero_filled_state(batch_size, self.cell.state_size,\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2518\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2519\u001b[0m     return list(_generate_zero_filled_state_for_cell(\n\u001b[1;32m-> 2520\u001b[1;33m         self, inputs, batch_size, dtype))\n\u001b[0m\u001b[0;32m   2521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state_for_cell\u001b[1;34m(cell, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2962\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2963\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2964\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_generate_zero_filled_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state\u001b[1;34m(batch_size_tensor, state_size, dtype)\u001b[0m\n\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_zeros\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mcreate_zeros\u001b[1;34m(unnested_state_size)\u001b[0m\n\u001b[0;32m   2975\u001b[0m     \u001b[0mflat_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munnested_state_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2976\u001b[0m     \u001b[0minit_state_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_size_tensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mflat_dims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2977\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_state_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2746\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2747\u001b[1;33m     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2748\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_zeros_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2749\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[1;34m(shape, dtype, name)\u001b[0m\n\u001b[0;32m   2792\u001b[0m           \u001b[1;31m# Create a constant if it won't be very big. Otherwise create a fill\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2793\u001b[0m           \u001b[1;31m# op to prevent serialized GraphDefs from becoming too large.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2794\u001b[1;33m           \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2795\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2796\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_constant_if_small\u001b[1;34m(value, shape, dtype, name)\u001b[0m\n\u001b[0;32m   2730\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2731\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2732\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2733\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2734\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   3050\u001b[0m     \"\"\"\n\u001b[0;32m   3051\u001b[0m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[1;32m-> 3052\u001b[1;33m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[0;32m   3053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    846\u001b[0m         \u001b[1;34m\"Cannot convert a symbolic Tensor ({}) to a numpy array.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m         \u001b[1;34m\" This error may indicate that you're trying to pass a Tensor to\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m         \" a NumPy call, which is not supported\".format(self.name))\n\u001b[0m\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (lstm_6/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_features_by_wordbag():\n",
    "    ham, spam = load_all_files()  # 确保这个函数被正确定义并返回数据\n",
    "    x = ham + spam\n",
    "    y = [0] * len(ham) + [1] * len(spam)\n",
    "    max_features = 5000  # 定义 max_features\n",
    "    vectorizer = CountVectorizer(\n",
    "        decode_error='ignore',\n",
    "        strip_accents='ascii',\n",
    "        max_features=max_features,\n",
    "        stop_words='english',\n",
    "        max_df=1.0,\n",
    "        min_df=1\n",
    "    )\n",
    "    x = vectorizer.fit_transform(x)\n",
    "    x = x.toarray()\n",
    "    return x, y\n",
    "\n",
    "def do_rnn_wordbag(trainX, testX, trainY, testY):\n",
    "    # 由于 trainX 和 testX 已经是数值化的特征，不需要转换为文本\n",
    "    # 直接使用数值特征\n",
    "    max_document_length = max(trainX.shape[1], testX.shape[1])  # 获取最大特征长度\n",
    "\n",
    "    trainX_padded = pad_sequences(trainX, maxlen=max_document_length, padding='post', truncating='post')\n",
    "    testX_padded = pad_sequences(testX, maxlen=max_document_length, padding='post', truncating='post')\n",
    "\n",
    "    trainY_categorical = tf.keras.utils.to_categorical(trainY, num_classes=2)\n",
    "    testY_categorical = tf.keras.utils.to_categorical(testY, num_classes=2)\n",
    "\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=5000, output_dim=128, input_length=max_document_length),\n",
    "        Dropout(0.2),\n",
    "        LSTM(128, dropout=0.2),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(trainX_padded, trainY_categorical, validation_data=(testX_padded, testY_categorical),\n",
    "              batch_size=10, epochs=5, verbose=1)\n",
    "\n",
    "    loss, accuracy = model.evaluate(testX_padded, testY_categorical)\n",
    "    print(f\"Test accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# 假设 load_all_files 和 train_test_split 函数已经定义\n",
    "x, y = get_features_by_wordbag()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=0)\n",
    "\n",
    "do_rnn_wordbag(x_train, x_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
