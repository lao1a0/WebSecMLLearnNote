{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Reshape\n",
    "from keras.optimizers import SGD\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "def func1():\n",
    "    print \"func1\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_shape=(784,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    plot_model(model, to_file='keras-demo1.png')\n",
    "    plot_model(model,show_shapes=True, to_file='keras-demo2.png')\n",
    "\n",
    "def func2():\n",
    "    x = np.arange(-5.0, 5.0, 0.02)\n",
    "    #y = np.sin(x)\n",
    "    y=(np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
    "\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y tanh(x)')\n",
    "    plt.title('tanh')\n",
    "\n",
    "    plt.plot(x, y)\n",
    "    plt.show()\n",
    "\n",
    "def func3():\n",
    "    x = np.arange(-5.0, 5.0, 0.02)\n",
    "    #y = np.sin(x)\n",
    "    y=1/(1+np.exp(-x))\n",
    "\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y sigmoid(x)')\n",
    "    plt.title('sigmoid')\n",
    "\n",
    "    plt.plot(x, y)\n",
    "    plt.show()\n",
    "\n",
    "def relu(x):\n",
    "    if x > 0:\n",
    "        return x\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def func4():\n",
    "    x = np.arange(-5.0, 5.0, 0.02)\n",
    "    y=[]\n",
    "\n",
    "    for i in x:\n",
    "        yi=relu(i)\n",
    "        y.append(yi)\n",
    "\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y relu(x)')\n",
    "    plt.title('relu')\n",
    "\n",
    "    plt.plot(x, y)\n",
    "    plt.show()\n",
    "\n",
    "def leakyrelu(x):\n",
    "    if x > 0:\n",
    "        return x\n",
    "    else:\n",
    "        return x*0.1\n",
    "\n",
    "def func5():\n",
    "    x = np.arange(-5.0, 5.0, 0.02)\n",
    "    y=[]\n",
    "\n",
    "    for i in x:\n",
    "        yi=leakyrelu(i)\n",
    "        y.append(yi)\n",
    "\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y leakyrelu(x)')\n",
    "    plt.title('leakyrelu')\n",
    "\n",
    "    plt.plot(x, y)\n",
    "    plt.show()\n",
    "\n",
    "def func6():\n",
    "    batch_size = 128\n",
    "    num_classes = 10\n",
    "    epochs = 20\n",
    "    # the data, shuffled and split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    x_train = x_train.reshape(60000, 784)\n",
    "    x_test = x_test.reshape(10000, 784)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    plot_model(model, show_shapes=True, to_file='keras-mlp.png')\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "def func7():\n",
    "    batch_size = 128\n",
    "    num_classes = 10\n",
    "    epochs = 12\n",
    "\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 28, 28\n",
    "\n",
    "    # the data, shuffled and split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    plot_model(model, show_shapes=True, to_file='keras-cnn.png')\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "def func8():\n",
    "    max_features = 20000\n",
    "    maxlen = 80\n",
    "    batch_size = 32\n",
    "\n",
    "    print('Loading data...')\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "    print(len(x_train), 'train sequences')\n",
    "    print(len(x_test), 'test sequences')\n",
    "\n",
    "    print('Pad sequences (samples x time)')\n",
    "    x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "    x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print('x_test shape:', x_test.shape)\n",
    "\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 128))\n",
    "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # try using different optimizers and different optimizer configs\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    plot_model(model, show_shapes=True, to_file='keras-lstm.png')\n",
    "\n",
    "    print('Train...')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=10,\n",
    "              validation_data=(x_test, y_test))\n",
    "    score, acc = model.evaluate(x_test, y_test,\n",
    "                                batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "\n",
    "def maidou_gan():\n",
    "    def gan_generator_model():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(input_dim=200, units=256))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(28*28*1))\n",
    "        model.add(Activation('sigmoid'))\n",
    "\n",
    "        model.add(Reshape((28, 28, 1), input_shape=(28*28*1,)))\n",
    "\n",
    "        plot_model(model, show_shapes=True, to_file='keras-gan-generator_model.png')\n",
    "        return model\n",
    "\n",
    "    def gan_discriminator_model():\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Reshape((28*28*1,), input_shape=(28, 28, 1)))\n",
    "        model.add(Dense(units=256))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('sigmoid'))\n",
    "\n",
    "        plot_model(model, show_shapes=True, to_file='keras-gan-discriminator_model.png')\n",
    "        return model\n",
    "\n",
    "    def gan_generator_containing_discriminator(g, d):\n",
    "        model = Sequential()\n",
    "        model.add(g)\n",
    "        d.trainable = False\n",
    "        model.add(d)\n",
    "\n",
    "        plot_model(model, show_shapes=True, to_file='keras-gan-gan_model.png')\n",
    "        return model\n",
    "\n",
    "    def gan_combine_images(generated_images):\n",
    "\n",
    "        #print generated_images.shape[0]\n",
    "\n",
    "        num = generated_images.shape[0]\n",
    "        width = int(math.sqrt(num))\n",
    "        height = int(math.ceil(float(num) / width))\n",
    "        shape = generated_images.shape[1:3]\n",
    "        image = np.zeros((height * shape[0], width * shape[1]),\n",
    "                         dtype=generated_images.dtype)\n",
    "        for index, img in enumerate(generated_images):\n",
    "            i = int(index / width)\n",
    "            j = index % width\n",
    "            image[i * shape[0]:(i + 1) * shape[0], j * shape[1]:(j + 1) * shape[1]] = \\\n",
    "                img[:, :, 0]\n",
    "        return image\n",
    "\n",
    "    def gan_train(BATCH_SIZE):\n",
    "        (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "        #把像素点转化成小数\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = X_train[:, :, :, None]\n",
    "        X_test = X_test[:, :, :, None]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print X_train.shape\n",
    "        # X_train = X_train.reshape((X_train.shape, 1) + X_train.shape[1:])\n",
    "        d = gan_discriminator_model()\n",
    "        g = gan_generator_model()\n",
    "        d_on_g = gan_generator_containing_discriminator(g, d)\n",
    "        d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "        g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "        g.compile(loss='binary_crossentropy', optimizer='SGD')\n",
    "        d_on_g.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "        d.trainable = True\n",
    "        d.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "        for epoch in range(100):\n",
    "            print(\"Epoch is\", epoch)\n",
    "            print(\"Number of batches\", int(X_train.shape[0] / BATCH_SIZE))\n",
    "            for index in range(int(X_train.shape[0] / BATCH_SIZE)):\n",
    "                noise = np.random.uniform(-1, 1, size=(BATCH_SIZE, 200))\n",
    "                image_batch = X_train[index * BATCH_SIZE:(index + 1) * BATCH_SIZE]\n",
    "                generated_images = g.predict(noise, verbose=0)\n",
    "                if index % 200 == 0:\n",
    "                    image = gan_combine_images(generated_images)\n",
    "                    #之前为了处理方便 像素都是0-1的小数 这里需要还原成整数\n",
    "                    image = image * 127.5 + 127.5\n",
    "                    # 调试阶段不生成图片\n",
    "                    Image.fromarray(image.astype(np.uint8)).save(\"gan/\"+str(epoch)+\"_\"+str(index)+\".png\")\n",
    "                X = np.concatenate((image_batch, generated_images))\n",
    "                y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "                d_loss = d.train_on_batch(X, y)\n",
    "                print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
    "                noise = np.random.uniform(-1, 1, (BATCH_SIZE, 200))\n",
    "                d.trainable = False\n",
    "                g_loss = d_on_g.train_on_batch(noise, [1] * BATCH_SIZE)\n",
    "                d.trainable = True\n",
    "                print(\"batch %d g_loss : %f\" % (index, g_loss))\n",
    "                if index % 100 == 0:\n",
    "                    g.save_weights('gan_generator', True)\n",
    "                    d.save_weights('gan_discriminator', True)\n",
    "\n",
    "    print \"maidou\"\n",
    "    gan_train(BATCH_SIZE=128)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    maidou_gan()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
