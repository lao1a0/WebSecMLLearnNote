{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "def func8():\n",
    "    max_features = 20000\n",
    "    maxlen = 80\n",
    "    batch_size = 32\n",
    "\n",
    "    print('Loading data...')\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "    print(len(x_train), 'train sequences')\n",
    "    print(len(x_test), 'test sequences')\n",
    "\n",
    "    print('Pad sequences (samples x time)')\n",
    "    x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "    x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print('x_test shape:', x_test.shape)\n",
    "\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 128))\n",
    "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # try using different optimizers and different optimizer configs\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    plot_model(model, show_shapes=True, to_file='keras-lstm.png')\n",
    "\n",
    "    print('Train...')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=10,\n",
    "              validation_data=(x_test, y_test))\n",
    "    score, acc = model.evaluate(x_test, y_test,\n",
    "                                batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "\n",
    "func8()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 –*-\n",
    "import gym\n",
    "import time\n",
    "import random\n",
    "\n",
    "states = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "actions = ['n', 'e', 's', 'w']\n",
    "\n",
    "def greedy(Q,state):\n",
    "    amax = 0\n",
    "    key = \"%d_%s\" % (state, actions[0])\n",
    "\n",
    "    qmax = Q[key]\n",
    "    for i in range(len(actions)):\n",
    "        key = \"%d_%s\" % (state, actions[i])\n",
    "        q = Q[key]\n",
    "        if qmax < q:\n",
    "            qmax = q\n",
    "            amax = i\n",
    "    return actions[amax]\n",
    "\n",
    "def epsilon_greedy(Q, state, epsilon):\n",
    "    amax = 0\n",
    "    key = \"%d_%s\"%(state, actions[0])\n",
    "    qmax = Q[key]\n",
    "    for i in range(len(actions)):\n",
    "        key = \"%d_%s\"%(state, actions[i])\n",
    "        q = Q[key]\n",
    "        if qmax < q:\n",
    "            qmax = q\n",
    "            amax = i\n",
    "\n",
    "    pro = [0.0 for i in range(len(actions))]\n",
    "    pro[amax] += 1-epsilon\n",
    "    for i in range(len(actions)):\n",
    "        pro[i] += epsilon/len(actions)\n",
    "\n",
    "\n",
    "    r = random.random()\n",
    "    s = 0.0\n",
    "    for i in range(len(actions)):\n",
    "        s += pro[i]\n",
    "        if s>= r: return actions[i]\n",
    "    return actions[len(actions)-1]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    env = gym.make('Gold-v0')\n",
    "    alpha=0.1\n",
    "    gamma=0.9\n",
    "    epsilon=0.1\n",
    "    random.seed(0)\n",
    "\n",
    "    Q = dict()\n",
    "\n",
    "    for s in states:\n",
    "        for a in actions:\n",
    "            key = \"%d_%s\"%(s,a)\n",
    "            Q[key]=0\n",
    "\n",
    "    gold=0\n",
    "    bad=0\n",
    "    good=0\n",
    "\n",
    "    for episode in range(1000):\n",
    "        s0 = env.reset()\n",
    "        a0 = epsilon_greedy(Q,s0,epsilon)\n",
    "\n",
    "        #狗屎运 初始化就拿到金币了\n",
    "        if s0 == 7 :\n",
    "            good+=1\n",
    "            continue\n",
    "\n",
    "        if s0 == 6 or s0 == 8 :\n",
    "            bad+=1\n",
    "            continue\n",
    "\n",
    "\n",
    "        #print(\"Episode start at state:{}\".format(s0))\n",
    "        for t in range(20):\n",
    "            observation, reward, done, info = env.step(a0)\n",
    "            s1=observation\n",
    "            #贪婪算法\n",
    "            #a1 = greedy(Q, s1)\n",
    "            #epsilon贪婪算法\n",
    "            a1 = epsilon_greedy(Q,s1,epsilon)\n",
    "\n",
    "            key0=   \"%d_%s\" % (s0, a0)\n",
    "            key1 = \"%d_%s\" % (s1, a1)\n",
    "            #更新Q函数\n",
    "            Q[key0] = Q[key0] + alpha * (reward + gamma * Q[key1] - Q[key0])\n",
    "            a0=a1\n",
    "            s0=s1\n",
    "            if done and s1==7 :\n",
    "                print(\"Get Gold {}th Episode finished after {} timesteps \".format(episode,t+1))\n",
    "                gold+=1\n",
    "                break\n",
    "            if done :\n",
    "                #print(\"Episode finished after {} timesteps \".format(t + 1))\n",
    "                break\n",
    "\n",
    "\n",
    "    print(\"episode:{} get gold:{} bad luck:{} good luck:{} lose:{}\".format(episode,gold,bad,good,episode-gold-good-bad))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
